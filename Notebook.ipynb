{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Implementation of Random Forests in a Classification problem\n",
    "\n",
    "Random Forest is a supervised learning machine learning algorithm. It consists of multiple Decision Trees.\n",
    "Random forests algorithm creates decision trees on randomly selected data samples, gets prediction from each tree and selects the best solution by means of voting. While this process takes place, the feature importances of each classification surface.\n",
    "\n",
    "## The Algorithm\n",
    "There are 4 steps in this algorithm:\n",
    "1. Random selection of data from the training set in form of samples\n",
    "2. Construct a Decision tree for each selected sample\n",
    "3. Score out each Decision tree \n",
    "4. Select the prediction result with the Highest as the final prediction\n",
    "\n",
    "## Advantages of Random Forests \n",
    "1. highly accurate and robust method because of the quantity of decision trees that make the entire classifier\n",
    "2. Does not suffer overfitting because all prediction values are averaged\n",
    "3. Classification and regression problems both can be handled by the Random Forest\n",
    "4. Random forests can also handle missing values\n",
    "5. Gives an idea of feature importance\n",
    "\n",
    "## Data Description\n",
    "The data which we will be dealing with in this example is the famous Titanic Survival data.\n",
    "The Titanic was the world's biggest ship to ever sail. It carried over  3,300 passengers.\n",
    "Unfortunately, it met with an accident and due to poor disaster planning, people died in the shipwreck\n",
    "The goal is to find if a passenger of the Titanic survived the shipwreck, given some data about these passengers(eg their class and how much their fare).\n",
    "\n",
    "We will be using scikit learn to train our model in python and matplotlib for visualization.\n",
    "\n",
    "\n",
    "### Features of the data\n",
    "1. pclass = A proxy for socio-economic status (SES)\n",
    "    1st = Upper\n",
    "    2nd = Middle\n",
    "    3rd = Lower\n",
    "\n",
    "2. age = Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "3. sibsp = The dataset defines family relations\n",
    "4. parch: The dataset defines family relations\n",
    "5. Survived  = 1 if the person survived, 0 if the person doesnot survive\n",
    "6. Embarked = where the person boarded the ship \n",
    "7. sex = gender of the person\n",
    "8. Fare = price of ticket paid by the passenger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#loading the data\n",
    "df = pd.read_csv('data.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting our X and y, features  and answers\n",
    "X = df[['PassengerId', 'Pclass', 'Name', 'Sex', 'Age',\n",
    "        'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are a few columns that might not play a part in deciding whether a passenger survived\n",
    "eg. PassengerId is just an index number and does not affect if the passenger survived or not. Likewise the name of the person also does not play a role in the passenger's survival.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping or removing all the columns that have no relations with the answer\n",
    "X = X.drop(['PassengerId', 'Embarked', 'Name', 'Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the gender variable because it has string values, while the classifier model takes only numerical format\n",
    "# All males will be 1 and all females will be 0 or vice versa\n",
    "le = LabelEncoder()\n",
    "X['Sex'] = le.fit_transform(X['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0 : Pclass, Score: 0.11342\n",
      "Feature 1 : Sex, Score: 0.30525\n",
      "Feature 2 : Age, Score: 0.23370\n",
      "Feature 3 : SibSp, Score: 0.04853\n",
      "Feature 4 : Parch, Score: 0.01377\n",
      "Feature 5 : Fare, Score: 0.28533\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple imputation to fill in all missing values, we will be filling it with mean values in the column\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# Feature Engineering  - Understanding which features play a role in passenger survival the most\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "importance = model.feature_importances_\n",
    "for i, v in enumerate(importance):\n",
    "    print('Feature %d : %s, Score: %.5f' % (i, X.columns[i], v))\n",
    "featurevsimp = plt.bar([x for x in range(len(importance))], importance)\n",
    "featurevsimp = plt.xlabel(\"Features\")\n",
    "featurevsimp = plt.ylabel(\"Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We come to know that the most important features that decide the output, we can drop the low score columns. But for the sake of simplicity, we can consider those columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing data (70% training and 30% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model defination\n",
    "\n",
    "# We need to choose how many trees are ideal in solving the problem. Too many trees in the Random forest classifier\n",
    "\n",
    "estimators = [10, 20, 40, 50, 100, 200, 300, 400]\n",
    "scores = []\n",
    "temp = {}\n",
    "\n",
    "for estimator in estimators:\n",
    "    clf = RandomForestClassifier(n_estimators=estimator) # preparing the model classifier\n",
    "    clf.fit(X_train, y_train)                            # Fitting the model to the training data\n",
    "    y_pred = clf.predict(X_test)                         # prediction on the testing data\n",
    "    score = metrics.accuracy_score(y_test, y_pred)       # scoring how well the model performed \n",
    "    scores.append(score)\n",
    "    temp[score] = estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained the model on a set of estimators, which are the number of trees the Random Forest consists of. The Lesser the number of trees, lesser features are picked, the more the number of trees, more intensively the features are picked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1]\n",
      "[0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1]\n",
      "Accuracy :  80.40712468193384 %\n",
      "Total Test Cases :  393\n",
      "Correct Predictions :  316.0\n",
      "Wrong Predictions :  77.0\n"
     ]
    }
   ],
   "source": [
    "# printing the results and the final take on the model\n",
    "bestEstimator = temp[max(scores)]\n",
    "clf = RandomForestClassifier(n_estimators=bestEstimator)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred.tolist())\n",
    "print(y_test.values.tolist())\n",
    "print(\"Accuracy : \", max(scores) * 100, \"%\")\n",
    "print(\"Total Test Cases : \", len(y_pred))\n",
    "print(\"Correct Predictions : \",  (max(scores) * len(y_pred)))\n",
    "print(\"Wrong Predictions : \",  len(y_pred) - (max(scores) * len(y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We have successfully built a model to classify the titanic dataset. The model can classify people who survived and people who died with an accuracy of 80%.\n",
    "\n",
    "Random forests present estimates for variable importance, i.e., neural nets. They also offer a superior method for working with missing data. Missing values are substituted by the variable appearing the most in a particular node. Among all the available classification methods, random forests provide the highest accuracy.\n",
    "\n",
    "The random forest technique can also handle big data with numerous variables running into thousands. It can automatically balance data sets when a class is more infrequent than other classes in the data. The method also handles variables fast, making it suitable for complicated tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
